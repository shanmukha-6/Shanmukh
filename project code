import numpy as
np import pandas
as pd
import matplotlib.pyplot as plt
# Set random seed for reproducibility 
np.random.seed(42)
# Number ofsamples 
num_samples = 2000
# Generate synthetic data
dates = pd.date_range(start='1/1/2010', periods=num_samples, freq='D')
prices = np.sin(np.linspace(0, 20, num_samples)) * 20 + np.random.normal(0, 1, 
num_samples) + 100
# Create DataFrame
synthetic_data = pd.DataFrame({'Date': dates, 'Close':
prices}) synthetic_data['Date'] =
pd.to_datetime(synthetic_data['Date']) 
synthetic_data.set_index('Date', inplace=True)
# Save the dataset to a CSV file 
synthetic_data.to_csv('synthetic_stock_data.csv') 
plt.bar(synthetic_data.index, synthetic_data['Close']) 
plt.xlabel('Date')
plt.ylabel('Price') 
plt.title('Synthetic Stock Data') 
plt.show()
plt.hist(synthetic_data['Close'], bins=20) 
plt.xlabel('Price')
plt.ylabel('Frequency') 
plt.title('Distribution of Prices') 
plt.show()
print("Synthetic dataset created successfully!")
ARIMA MODEL:
import pandas as pd
fromstatsmodels.tsa.arima.model import
ARIMA import matplotlib.pyplot as plt
# Load the dataset
data = pd.read_csv('synthetic_stock_data.csv', index_col='Date', parse_dates=True)
# Train ARIMA model
arima_model = ARIMA(data['Close'], order=(5, 1, 0)) 
arima_model_fit = arima_model.fit()
# Make predictions
predictions = arima_model_fit.forecast(steps=30) 
plt.figure(figsize=(14, 7))
plt.plot(data['Close'], label='Actual Prices') 
plt.plot(predictions, label='Predicted Prices', 
color='red') plt.title('ARIMA Model Predictions')
plt.xlabel('Date') 
plt.ylabel('Price') 
plt.legend() 
plt.show()
LSTM MODEL:
import numpy as
np import pandas
as pd
from sklearn.preprocessing import MinMaxScaler 
from tensorflow.keras.models import Sequential 
from tensorflow.keras.layers import LSTM, Dense 
import matplotlib.pyplot as plt
# Load the dataset
data = pd.read_csv('synthetic_stock_data.csv', index_col='Date',
parse_dates=True) data = data['Close'].values.reshape(-1, 1)
# Normalize the data
scaler = MinMaxScaler(feature_range=(0,
1)) scaled_data = 
scaler.fit_transform(data)
# Prepare the data for LSTM 
look_back = 60
X, y = [], []
for i in range(look_back,
len(scaled_data)): 
X.append(scaled_data[i-look_back:i,
0])
y.append(scaled_data[i, 0])
X, y = np.array(X), np.array(y)
X = np.reshape(X, (X.shape[0], X.shape[1], 1))
# Split the data into training and testing sets 
train_size = int(len(X) * 0.8)
X_train, X_test = X[:train_size],
X[train_size:] y_train, y_test = 
y[:train_size], y[train_size:]
# Build the LSTM model 
model = Sequential([
LSTM(50, return_sequences=True, input_shape=(look_back, 1)), 
LSTM(50, return_sequences=False),
Dense(25), 
Dense(1)
])
model.compile(optimizer='adam', loss='mean_squared_error') 
model.fit(X_train, y_train, epochs=10, batch_size=32)
# Make predictions
train_predict = model.predict(X_train) 
test_predict = model.predict(X_test)
# Invert predictions
train_predict = scaler.inverse_transform(train_predict) 
test_predict = scaler.inverse_transform(test_predict) 
y_train = scaler.inverse_transform([y_train])
y_test = scaler.inverse_transform([y_test])
# Plot the predictions 
plt.figure(figsize=(14, 7)) 
plt.plot(data, label='Actual Prices')
plt.plot(np.arange(look_back, len(train_predict)+look_back), train_predict, label='Train 
Predictions', color='orange')
plt.plot(np.arange(len(train_predict)+(2*look_back), 
len(train_predict)+(2*look_back)+len(test_predict)), test_predict, label='Test 
Predictions', color='red')
plt.title('LSTM Model Predictions') 
plt.xlabel('Date')
plt.ylabel('Price') 
plt.legend() 
plt.show()
RANDOM FOREST MODEL:
from sklearn.ensemble import
RandomForestRegressor from 
sklearn.model_selection import train_test_split from 
sklearn.metrics import mean_squared_error
# Load the dataset
data = pd.read_csv('synthetic_stock_data.csv', index_col='Date', parse_dates=True)
# Create features and labels 
data['Target'] = data['Close'].shift(-
30) features =
data.drop(columns=['Target']) labels = 
data['Target'].dropna()
X = features[:-
30] y = labels
# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)
# Train Random Forest model
rf_model = RandomForestRegressor(n_estimators=100, random_state=42) 
rf_model.fit(X_train, y_train)
# Make predictions
rf_predictions = rf_model.predict(X_test)
# Evaluate the model
mse = mean_squared_error(y_test, rf_predictions) 
print('Random Forest MSE:', mse)
plt.figure(figsize=(14, 7))
plt.bar(y_test.index, y_test, label='Actual
Prices') plt.show()
plt.figure(figsize=(14, 7))
plt.bar(y_test.index, rf_predictions, label='Predicted Prices', color='red') 
plt.show()
# Plot the predictions 
plt.figure(figsize=(14, 7))
plt.bar(y_test.index, y_test, label='Actual Prices')
plt.bar(y_test.index, rf_predictions, label='Predicted Prices', color='red') 
plt.title('Random Forest Model Predictions')
plt.xlabel('Date') 
plt.ylabel('Price')
plt.legend() 
plt.show()
from sklearn.ensemble import
RandomForestRegressor from 
sklearn.model_selection import train_test_split from 
sklearn.metrics import mean_squared_error import 
pandas as pd
import matplotlib.pyplot as plt
# ... (Your existing code for loading and training the model)
... # Get user input
start_date = input("Enter start date (YYYY-MM-DD): ") 
end_date = input("Enter end date (YYYY-MM-DD): ")
# Filter data
filtered_data = data[(data.index >= start_date) & (data.index <= end_date)]
# Prepare data for prediction 
X_pred =
filtered_data[['Close']]
# Make predictions
dynamic_predictions = rf_model.predict(X_pred)
# Visualize predictions 
plt.figure(figsize=(14, 7))
plt.bar(filtered_data.index, filtered_data['Close'], label='Actual Prices') 
plt.bar(filtered_data.index, dynamic_predictions, label='Predicted Prices',
color='red') plt.title('Random Forest Model Predictions (Dynamic)')
plt.xlabel('Date') 
plt.ylabel('Price') 
plt.legend() 
plt.show()
